{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T10:39:07.789092Z",
     "start_time": "2024-06-24T10:39:06.416302Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torch.nn import functional as F\n",
    "import torch.autograd as autograd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:01:02.618077Z",
     "start_time": "2024-06-23T15:01:02.596697Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias).float()\n",
    "\n",
    "        self.physics_conv = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                      out_channels=4 * self.hidden_dim,\n",
    "                                      kernel_size=self.kernel_size,\n",
    "                                      padding=self.padding,\n",
    "                                      bias=False).float()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        # Check if input_tensor has an extra dimension (sequence length)\n",
    "        if input_tensor.dim() == 5:\n",
    "            input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        physics_conv = self.physics_conv(input_tensor)\n",
    "\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        pc_i, pc_f, pc_o, pc_g = torch.split(physics_conv, self.hidden_dim, dim=1)\n",
    "\n",
    "        i = torch.sigmoid(cc_i + pc_i)\n",
    "        f = torch.sigmoid(cc_f + pc_f)\n",
    "        o = torch.sigmoid(cc_o + pc_o)\n",
    "        g = torch.tanh(cc_g + pc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM_iPINN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,output_dim,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM_iPINN, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "        # Initialize velocities as trainable parameters\n",
    "        self.velocity_x = nn.Parameter(torch.tensor(0.1))\n",
    "        self.velocity_y = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "        self.output_conv = nn.Conv2d(in_channels=hidden_dim[-1],\n",
    "                                      out_channels=output_dim,\n",
    "                                      kernel_size=1,\n",
    "                                      padding=0)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        if input_tensor.dim() == 4:\n",
    "            # (b, h, w, c) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "        elif input_tensor.dim() == 5:\n",
    "            if not self.batch_first:\n",
    "                # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "                input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, t, _, h, w = input_tensor.size()\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        # Remove the sequence length dimension before applying the output convolution\n",
    "        output = self.output_conv(layer_output_list[0].squeeze(1))\n",
    "        # Permute the output to have shape (b, h, w, c)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        return output, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param\n",
    "\n",
    "    def advection_loss(self, input_tensor, output_tensor):\n",
    "        grad = torch.autograd.grad(outputs=output_tensor, inputs=input_tensor,\n",
    "                                   grad_outputs=torch.ones_like(output_tensor), create_graph=True)[0]\n",
    "        dudx = grad[:, :, 0]\n",
    "        dudy = grad[:, :, 1]\n",
    "        dudt = grad[:, :, 2]\n",
    "\n",
    "        physics = dudt + self.velocity_x * dudx + self.velocity_y * dudy\n",
    "        loss = torch.mean((physics) ** 2)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:01:08.490717Z",
     "start_time": "2024-06-23T15:01:07.724739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushen/anaconda3/envs/pinn/lib/python3.11/site-packages/matplotlib/animation.py:892: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load radar data\n",
    "movies = np.load('/home/sushen/PhysNet-RadarNowcast/tests/5rect_movie.npy')\n",
    "movies.shape # (980, 40, 40, 20) -- here each movie is of length 20\n",
    "\n",
    "# in our model we will use the first four images as inputs and predict the\n",
    "# fifth image\n",
    "x = movies[:, :, :,  :4]\n",
    "y = movies[:, :, :, 4:5]\n",
    "\n",
    "\n",
    "# function: animation of a sequence of radar data (shape = nx,ny,ntime)\n",
    "def animate(x):\n",
    "  fig, ax = plt.subplots()\n",
    "  vmax = np.max(x)\n",
    "  im = ax.imshow(x[:,:,0], vmin=0, vmax=vmax)\n",
    "  fig.colorbar(im)\n",
    "  plt.axis('off')\n",
    "  def anim_(i):\n",
    "      im.set_data(x[:,:,i])\n",
    "      ax.set_title(str(i+1) + '/' + str(x.shape[2]))\n",
    "  anim = animation.FuncAnimation(\n",
    "      fig, anim_, interval=300, frames=x.shape[2], repeat_delay=1000)\n",
    "  plt.show()\n",
    "\n",
    "# i_plt = 340\n",
    "# i_plt = 123\n",
    "i_plt = np.int32(np.random.sample() * movies.shape[0])\n",
    "animate(x[i_plt,:,:,:])\n",
    "plt.show()\n",
    "\n",
    "# train validate test split\n",
    "tvt = np.tile(['train','train','train','validate','test'], y.shape[0])[:y.shape[0]]\n",
    "x_train = x[np.where(tvt == 'train')]\n",
    "y_train = y[np.where(tvt == 'train')]\n",
    "x_validate = x[np.where(tvt == 'validate')]\n",
    "y_validate = y[np.where(tvt == 'validate')]\n",
    "x_test = x[np.where(tvt == 'test')]\n",
    "y_test = y[np.where(tvt == 'test')]\n",
    "\n",
    "n_test = x_test.shape[0]\n",
    "i_plt = np.int32(np.random.sample() * n_test)\n",
    "true = np.append(x_test[i_plt,:,:,:], y_test[i_plt,:,:,:], axis=2)\n",
    "# plot an input/output pair\n",
    "i_plt = 20\n",
    "i_plt = np.int32(np.random.sample() * x_train.shape[0])\n",
    "for jj in range(4):\n",
    "  plt.subplot(1,5,jj+1)\n",
    "  plt.imshow(x_train[i_plt,:,:,jj])\n",
    "  plt.axis('off')\n",
    "  plt.title('input')\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(y_train[i_plt,:,:,0])\n",
    "plt.title('target output')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:01:14.037737Z",
     "start_time": "2024-06-23T15:01:12.285691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available()\n",
    "     \n",
    "    \n",
    "      )\n",
    "def update_grid(rin_physics):\n",
    "    # Get the shape of the input tensor\n",
    "    shape = rin_physics.shape\n",
    "    # Create an empty tensor with the same shape\n",
    "    updated_grid = np.zeros(shape)\n",
    "\n",
    "    # Iterate through each element in the batch\n",
    "    for i in range(shape[0]):\n",
    "        # Extract the individual grid\n",
    "        grid = rin_physics[i]\n",
    "\n",
    "        # Find the max and min x, y values\n",
    "        max_x, max_y = np.unravel_index(np.argmax(grid[:, :, 0]), grid[:, :, 0].shape)\n",
    "        min_x, min_y = np.unravel_index(np.argmin(grid[:, :, 0]), grid[:, :, 0].shape)\n",
    "\n",
    "        # Set the pattern\n",
    "        updated_grid[i, max_x, max_y, :] = 1\n",
    "        updated_grid[i, min_x, min_y, :] = 0\n",
    "\n",
    "    return updated_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:09:35.782099Z",
     "start_time": "2024-06-23T15:09:35.646265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (588, 40, 40, 4)\n",
      "x_validate shape: (196, 40, 40, 4)\n",
      "x_test shape: (196, 40, 40, 4)\n",
      "y_train shape: (588, 40, 40, 1)\n",
      "y_validate shape: (196, 40, 40, 1)\n",
      "y_test shape: (196, 40, 40, 1)\n",
      "Epoch [1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207797/3371233068.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0045, Val Loss: 0.0029\n",
      "Epoch [2/100]\n",
      "Train Loss: 0.0028, Val Loss: 0.0029\n",
      "Epoch [3/100]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [4/100]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [5/100]\n",
      "Train Loss: 0.0027, Val Loss: 0.0027\n",
      "Epoch [6/100]\n",
      "Train Loss: 0.0026, Val Loss: 0.0026\n",
      "Epoch [7/100]\n",
      "Train Loss: 0.0024, Val Loss: 0.0024\n",
      "Epoch [8/100]\n",
      "Train Loss: 0.0023, Val Loss: 0.0023\n",
      "Epoch [9/100]\n",
      "Train Loss: 0.0022, Val Loss: 0.0023\n",
      "Epoch [10/100]\n",
      "Train Loss: 0.0022, Val Loss: 0.0023\n",
      "Epoch [11/100]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [12/100]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [13/100]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [14/100]\n",
      "Train Loss: 0.0021, Val Loss: 0.0021\n",
      "Epoch [15/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [16/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [17/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [18/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [19/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [20/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0021\n",
      "Epoch [21/100]\n",
      "Train Loss: 0.0020, Val Loss: 0.0020\n",
      "Epoch [22/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [23/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [24/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [25/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [26/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [27/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [28/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [29/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [30/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [31/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [32/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [33/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [34/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [35/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [36/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [37/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [38/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [39/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [40/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [41/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [42/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0020\n",
      "Epoch [43/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [44/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [45/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [46/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [47/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [48/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [49/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [50/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [51/100]\n",
      "Train Loss: 0.0019, Val Loss: 0.0019\n",
      "Epoch [52/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [53/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [54/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [55/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [56/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [57/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [58/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [59/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [60/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [61/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [62/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [63/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [64/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [65/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [66/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [67/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [68/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [69/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [70/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [71/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [72/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [73/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [74/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [75/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [76/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [77/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [78/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [79/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [80/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [81/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [82/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [83/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [84/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [85/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [86/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [87/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [88/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [89/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0019\n",
      "Epoch [90/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [91/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [92/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [93/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [94/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [95/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [96/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [97/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [98/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [99/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Epoch [100/100]\n",
      "Train Loss: 0.0018, Val Loss: 0.0018\n",
      "Test Loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming x_train, x_validate, x_test, y_train, y_validate, and y_test are defined\n",
    "print(\"x_train shape:\", np.shape(x_train))\n",
    "print(\"x_validate shape:\", np.shape(x_validate))\n",
    "print(\"x_test shape:\", np.shape(x_test))\n",
    "print(\"y_train shape:\", np.shape(y_train))\n",
    "print(\"y_validate shape:\", np.shape(y_validate))\n",
    "print(\"y_test shape:\", np.shape(y_test))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float().requires_grad_(), torch.from_numpy(y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(x_validate).float().requires_grad_(), torch.from_numpy(y_validate).float())\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test).float().requires_grad_(), torch.from_numpy(y_test).float())\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = ConvLSTM_iPINN(input_dim=4, hidden_dim=40, kernel_size=(3, 3), num_layers=3, output_dim=1, bias=True, return_all_layers=False)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        # Enable gradients for the output tensor\n",
    "        output.requires_grad_(True)\n",
    "        \n",
    "        # Compute data loss\n",
    "        \n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Compute physics loss\n",
    "\n",
    "        # Create an empty tensor with the same shape as batch_x\n",
    "        rin_physics = torch.zeros_like(batch_x, device=device, requires_grad=True)\n",
    "        #rin_physics = update_grid(rin_physics.cpu().detach().numpy())\n",
    "        # print(rin_physics.shape, batch_x.shape)\n",
    "        # print(\"Shape after update_grid:\", rin_physics.shape)\n",
    "       # rin_physics = rin_physics.view(32, 40, 40, 4)  # Use view instead of reshape\n",
    "        rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n",
    "        \n",
    "        output, _ = model(rin_physics)\n",
    "        physics_loss = model.advection_loss(rin_physics, output)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss   +  physics_loss \n",
    "        \n",
    "        # loss = torch.max(0.5 * torch.abs(data_loss - physics_loss))\n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update weights and velocities\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, _ = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            \n",
    "            # Compute data loss\n",
    "            data_loss = criterion(output, batch_y)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Combine losses\n",
    "            loss = data_loss \n",
    "            \n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "       \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        # Compute data loss\n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss \n",
    "        \n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T09:01:32.361697Z",
     "start_time": "2024-05-29T09:01:32.361566Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import matplotlib.colors as mcolors\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def animate2(x1, x2, i_plt, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    vmax = np.max(np.append(x1, x2))\n",
    "    vmin = np.min(np.append(x1, x2))\n",
    "\n",
    "    frames = min(x1.shape[2], x2.shape[2])  # Get the minimum number of frames\n",
    "\n",
    "    # Initialize lists to store MAE and RMSE for each frame\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for i in range(frames):\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(18, 5))  # Adjust the figure size as needed\n",
    "\n",
    "        im1 = ax[0].imshow(x1[:, :, i], vmin=vmin, vmax=vmax)\n",
    "        im2 = ax[1].imshow(x2[:, :, i], vmin=vmin, vmax=vmax)\n",
    "\n",
    "        diff = x1[:, :, i] - x2[:, :, i]\n",
    "        vmin_diff, vmax_diff = np.min(diff), np.max(diff)\n",
    "        norm = mcolors.Normalize(vmin=vmin_diff, vmax=vmax_diff)\n",
    "        im3 = ax[2].imshow(diff, cmap='viridis', norm=norm)\n",
    "\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "        fig.colorbar(im3, cax=cbar_ax)\n",
    "\n",
    "        # Add labels\n",
    "        ax[0].set_title('Predicted')\n",
    "        ax[1].set_title('True')\n",
    "        ax[2].set_title('Difference')\n",
    "\n",
    "        # Remove axis ticks\n",
    "        for a in ax:\n",
    "            a.set_xticks([])\n",
    "            a.set_yticks([])\n",
    "\n",
    "        # Calculate MAE and RMSE for the current frame\n",
    "        mae = np.mean(np.abs(diff))\n",
    "        rmse = np.sqrt(np.mean(diff ** 2))\n",
    "\n",
    "        # Append MAE and RMSE to the lists\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "        # Add MAE and RMSE to the plot title\n",
    "        fig.suptitle(f'Physics informed ConvLSTM | i = {i_plt} Predict Frame - MAE: {mae:.4f}, RMSE: {rmse:.4f}', fontsize=12)\n",
    "\n",
    "        # Save the current frame as an image file\n",
    "        filename = f'PhyConvLSTMframe_{i_plt:04d}_{i+1:04d}.png'\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "        plt.savefig(filepath, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    # # Save MAE and RMSE for each frame to a CSV file\n",
    "    # csv_file = os.path.join(output_folder, f'mae_rmse_{i_plt:04d}.csv')\n",
    "    # with open(csv_file, mode='w', newline='') as file:\n",
    "    #     writer = csv.writer(file)\n",
    "    #     writer.writerow(['Frame', 'MAE', 'RMSE'])\n",
    "    #     for i in range(frames):\n",
    "    #         writer.writerow([i+1, mae_list[i], rmse_list[i]])\n",
    "\n",
    "    print(f\"Images and CSV file saved in the folder: {output_folder}\")\n",
    "\n",
    "# device = torch.device(\"cuda\")\n",
    "# # Convert y_test to a PyTorch tensor\n",
    "# y_test_tensor = torch.from_numpy(y_test).float()\n",
    "\n",
    "\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "# y_test_pred = torch.empty_like(y_test_tensor,device=device)  # Initialize an empty tensor to store predictions\n",
    "\n",
    "# with torch.no_grad():  # Disable gradient computation for inference\n",
    "#     for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "#         batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "#         outputs = model(batch_x)  # Get the model outputs for this batch\n",
    "        \n",
    "        \n",
    "\n",
    "#         y_test_pred[i * test_loader.batch_size:(i + 1) * test_loader.batch_size] = outputs  # Store the predictions\n",
    "        \n",
    "\n",
    "# # Now you have y_test_pred ready to use\n",
    "# # Assuming x_test, y_test, and y_test_pred are PyTorch tensors\n",
    "# n_test = x_test.shape[0]\n",
    "# i_plt = np.int32(np.random.sample() * n_test)\n",
    "\n",
    "# print('Showing test case i =', i_plt)\n",
    "\n",
    "# # Convert NumPy arrays to PyTorch tensors\n",
    "# x_test_tensor = torch.from_numpy(x_test).float()\n",
    "# y_test_tensor = torch.from_numpy(y_test).float()\n",
    "# # Assuming your model is defined and trained\n",
    "\n",
    "\n",
    "# # Repeat the channel dimension of y_test_tensor to match x_test_tensor\n",
    "\n",
    "\n",
    "# print(f'shape of x test tensor: {x_test_tensor[i_plt].shape}')\n",
    "# print(f'shape of y test tensor: {y_test_tensor[i_plt].shape}')\n",
    "# print(f'shape of y test pred: {y_test_pred[i_plt].shape}')\n",
    "\n",
    "# for i_plt in range(10):\n",
    "#     true = np.append(x_test[i_plt,:,:,:], y_test[i_plt,:,:,:], axis=2)\n",
    "#     pred = np.append(x_test[i_plt,:,:,:], y_test_pred.cpu()[i_plt,:,:,:], axis=2)\n",
    "\n",
    "#     anim = animate2(pred, true,i_plt,'/home/sushen/PhysNet-RadarNowcast/2d-advection/pinn_plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "\n",
    "def animate_comparison(model, data_loader, output_folder):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract a single batch for visualization\n",
    "    inputs, targets = next(iter(data_loader))\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = inputs.to(next(model.parameters()).device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs,states = model(inputs)\n",
    "    \n",
    "    # Assuming outputs and targets are on GPU, move them to CPU and convert to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    \n",
    "    # Prepare figure for animation\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    def update(i):\n",
    "        # Clear previous content\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "        \n",
    "        # Update content for frame i\n",
    "        ax[0].imshow(outputs[i].squeeze(), cmap='gray')\n",
    "        ax[0].set_title('Output')\n",
    "        ax[1].imshow(targets[i].squeeze(), cmap='gray')\n",
    "        ax[1].set_title('Target')\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(outputs), interval=200)\n",
    "    \n",
    "    # Save animation\n",
    "    anim.save(f'{output_folder}/comparison_animation.gif', writer='imagemagick')\n",
    "\n",
    "# Example usage\n",
    "animate_comparison(model, test_loader, '/home/sushen/PhysNet-RadarNowcast/images/convLSTM_iPINN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i_plt, (batch_x, batch_y) in enumerate(test_loader):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        \n",
    "        # Compute data loss\n",
    "        data_loss = criterion(output, batch_y)\n",
    "\n",
    "        # Combine losses\n",
    "        loss = data_loss\n",
    "\n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "        # Plot the results for the current batch\n",
    "        for j in range(batch_x.size(0)):\n",
    "            print(f'Batch {i_plt}, Sample {j}, batch_x.shape: {batch_x[j].shape}, batch_y.shape: {batch_y[j].shape}, output.shape: {output[j].shape}')\n",
    "            true = np.append(batch_x[j].cpu().numpy(), batch_y[j].cpu().numpy(), axis=2)\n",
    "            pred = np.append(batch_x[j].cpu().numpy(), output[j].cpu().numpy(), axis=2)\n",
    "            anim = animate2(pred, true, i_plt * batch_x.size(0) + j, '/home/sushen/PhysNet-RadarNowcast/2d-advection/pinn_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Set the directories where the images are located\n",
    "convlstm_dir = '/home/sushen/PhysNet-RadarNowcast/2d-advection/pinn_plot'\n",
    "phyconvlstm_dir = '/home/sushen/PhysNet-RadarNowcast/2d-advection/pinn_plot'\n",
    "\n",
    "# Set the output directory for the combined images\n",
    "output_dir = '/home/sushen/PhysNet-RadarNowcast/2d-advection/pinn_plot/10_combined_images'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Set the range of image numbers\n",
    "start_num = 0\n",
    "end_num = 191  # Inclusive\n",
    "# Set the font and font size for the text\n",
    "font_path = '/home/sushen/PhysNet-RadarNowcast/data/Ubuntu-BoldItalic.ttf'\n",
    "font_size = 18\n",
    "\n",
    "# Loop through the image numbers\n",
    "for i in range(start_num, end_num + 1):\n",
    "    # Generate the filenames for the current image pair\n",
    "    convlstm_filename = f'ConvLSTMframe_{i:04d}_{5:04d}.png'\n",
    "    phyconvlstm_filename = f'PhyConvLSTMframe_{i:04d}_{5:04d}.png'\n",
    "\n",
    "    # Open the images\n",
    "    convlstm_path = os.path.join(convlstm_dir, convlstm_filename)\n",
    "    phyconvlstm_path = os.path.join(phyconvlstm_dir, phyconvlstm_filename)\n",
    "\n",
    "    convlstm_image = Image.open(convlstm_path)\n",
    "    phyconvlstm_image = Image.open(phyconvlstm_path)\n",
    "\n",
    "    # Get the dimensions of the images\n",
    "    width, height = convlstm_image.size\n",
    "\n",
    "    # Create a new blank image with double the height\n",
    "    combined_image = Image.new('RGB', (width, height * 2))\n",
    "\n",
    "    # Paste the ConvLSTMframe image at the top\n",
    "    combined_image.paste(convlstm_image, (0, 0))\n",
    "\n",
    "    # Paste the PhyConvLSTMframe image at the bottom\n",
    "    combined_image.paste(phyconvlstm_image, (0, height))\n",
    "\n",
    "    # Save the combined image\n",
    "    output_filename = f'combined_frame_{i:04d}.png'\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    combined_image.save(output_path)\n",
    "\n",
    "    print(f'Combined image saved: {output_path}')\n",
    "\n",
    "print('All images combined successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
