{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T09:56:02.199285Z",
     "start_time": "2024-06-24T09:56:00.652282Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:57:22.858776Z",
     "start_time": "2024-06-24T09:57:22.842710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShiftingWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        pad_h = (self.window_size - H % self.window_size) % self.window_size\n",
    "        pad_w = (self.window_size - W % self.window_size) % self.window_size\n",
    "        x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h))\n",
    "        _, Hp, Wp, _ = x.shape\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, self.window_size, Wp // self.window_size, self.window_size, C)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size * self.window_size, C)\n",
    "\n",
    "        qkv = self.qkv(windows).reshape(-1, self.window_size * self.window_size, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(-1, self.window_size * self.window_size, C)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, Wp // self.window_size, self.window_size, self.window_size, C)\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, Hp, Wp, C)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = x[:, :H, :W, :].contiguous()\n",
    "        return x\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias, physics_kernel_size, window_size, num_heads):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.physics_conv_x = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[0] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.physics_conv_y = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[1] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.attention = ShiftingWindowAttention(hidden_dim, window_size, num_heads)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        if input_tensor.dim() == 5:\n",
    "            input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "        if input_tensor.size(1) != self.input_dim:\n",
    "            raise ValueError(f\"Expected input_tensor to have {self.input_dim} channels, but got {input_tensor.size(1)} channels instead\")\n",
    "\n",
    "        if h_cur.size(1) != self.hidden_dim:\n",
    "            raise ValueError(f\"Expected h_cur to have {self.hidden_dim} channels, but got {h_cur.size(1)} channels instead\")\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "\n",
    "        physics_conv_x = self.physics_conv_x(input_tensor)\n",
    "        physics_conv_y = self.physics_conv_y(input_tensor)\n",
    "\n",
    "        i = torch.sigmoid(cc_i + physics_conv_x)\n",
    "        f = torch.sigmoid(cc_f + physics_conv_x)\n",
    "        o = torch.sigmoid(cc_o + physics_conv_y)\n",
    "        g = torch.tanh(cc_g + physics_conv_y)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        # Apply shifting window attention\n",
    "        h_next = h_next.permute(0, 2, 3, 1)  # Change to (B, H, W, C)\n",
    "        h_next = self.attention(h_next)\n",
    "        h_next = h_next.permute(0, 3, 1, 2)  # Change back to (B, C, H, W)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, physics_kernel_size, output_dim,\n",
    "                 batch_first=False, bias=True, return_all_layers=False, window_size=8, num_heads=4):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias,\n",
    "                                          physics_kernel_size=physics_kernel_size,\n",
    "                                          window_size=window_size,\n",
    "                                          num_heads=num_heads))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.output_conv = nn.Conv2d(in_channels=hidden_dim[-1],\n",
    "                                     out_channels=output_dim,\n",
    "                                     kernel_size=1,\n",
    "                                     padding=0)\n",
    "        # Initialize velocities as trainable parameters\n",
    "        self.velocity_x = nn.Parameter(torch.tensor(0.1))\n",
    "        self.velocity_y = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "   \n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        if input_tensor.dim() == 4:\n",
    "            # (b, h, w, c) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "        elif input_tensor.dim() == 5:\n",
    "            if not self.batch_first:\n",
    "                # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "                input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, t, _, h, w = input_tensor.size()\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        # Remove the sequence length dimension before applying the output convolution\n",
    "        output = self.output_conv(layer_output_list[0].squeeze(1))\n",
    "        # Permute the output to have shape (b, h, w, c)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        return output, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param\n",
    "    \n",
    "    def advection_loss(self, input_tensor, output_tensor):\n",
    "        grad = torch.autograd.grad(outputs=output_tensor, inputs=input_tensor,\n",
    "                                   grad_outputs=torch.ones_like(output_tensor), create_graph=True)[0]\n",
    "        dudx = grad[:, :, 0]\n",
    "        dudy = grad[:, :, 1]\n",
    "        dudt = grad[:, :, 2]\n",
    "\n",
    "        physics = dudt + self.velocity_x * dudx + self.velocity_y * dudy\n",
    "        loss = torch.mean((physics) ** 2)\n",
    "\n",
    "        return loss"
   ],
   "id": "f2290a98f0fe48bf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:56:02.652801Z",
     "start_time": "2024-06-24T09:56:02.304543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load radar data\n",
    "movies = np.load('/home/sushen/PhysNet-RadarNowcast/tests/rect_movie.npy')\n",
    "movies.shape # (980, 40, 40, 20) -- here each movie is of length 20\n",
    "\n",
    "# in our model we will use the first four images as inputs and predict the\n",
    "# fifth image\n",
    "x = movies[:, :, :,  :4]\n",
    "y = movies[:, :, :, 4:5]\n",
    "\n",
    "\n",
    "# function: animation of a sequence of radar data (shape = nx,ny,ntime)\n",
    "def animate(x):\n",
    "  fig, ax = plt.subplots()\n",
    "  vmax = np.max(x)\n",
    "  im = ax.imshow(x[:,:,0], vmin=0, vmax=vmax)\n",
    "  fig.colorbar(im)\n",
    "  plt.axis('off')\n",
    "  def anim_(i):\n",
    "      im.set_data(x[:,:,i])\n",
    "      ax.set_title(str(i+1) + '/' + str(x.shape[2]))\n",
    "  anim = animation.FuncAnimation(\n",
    "      fig, anim_, interval=300, frames=x.shape[2], repeat_delay=1000)\n",
    "  plt.show()\n",
    "\n",
    "# i_plt = 340\n",
    "# i_plt = 123\n",
    "i_plt = np.int32(np.random.sample() * movies.shape[0])\n",
    "animate(x[i_plt,:,:,:])\n",
    "plt.show()\n",
    "\n",
    "# train validate test split\n",
    "tvt = np.tile(['train','train','train','validate','test'], y.shape[0])[:y.shape[0]]\n",
    "x_train = x[np.where(tvt == 'train')]\n",
    "y_train = y[np.where(tvt == 'train')]\n",
    "x_validate = x[np.where(tvt == 'validate')]\n",
    "y_validate = y[np.where(tvt == 'validate')]\n",
    "x_test = x[np.where(tvt == 'test')]\n",
    "y_test = y[np.where(tvt == 'test')]\n",
    "\n",
    "n_test = x_test.shape[0]\n",
    "i_plt = np.int32(np.random.sample() * n_test)\n",
    "true = np.append(x_test[i_plt,:,:,:], y_test[i_plt,:,:,:], axis=2)\n",
    "# plot an input/output pair\n",
    "i_plt = 20\n",
    "i_plt = np.int32(np.random.sample() * x_train.shape[0])\n",
    "for jj in range(4):\n",
    "  plt.subplot(1,5,jj+1)\n",
    "  plt.imshow(x_train[i_plt,:,:,jj])\n",
    "  plt.axis('off')\n",
    "  plt.title('input')\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(y_train[i_plt,:,:,0])\n",
    "plt.title('target output')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "e61b4bc43c4f8cce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushen/anaconda3/envs/pinn/lib/python3.11/site-packages/matplotlib/animation.py:892: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T09:56:02.751597Z",
     "start_time": "2024-06-24T09:56:02.653554Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.memory_summary(device=None, abbreviated=False)",
   "id": "c2ce273010cdf8ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T10:16:03.160591Z",
     "start_time": "2024-06-24T10:16:02.828322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming x_train, x_validate, x_test, y_train, y_validate, and y_test are defined\n",
    "print(\"x_train shape:\", np.shape(x_train))\n",
    "print(\"x_validate shape:\", np.shape(x_validate))\n",
    "print(\"x_test shape:\", np.shape(x_test))\n",
    "print(\"y_train shape:\", np.shape(y_train))\n",
    "print(\"y_validate shape:\", np.shape(y_validate))\n",
    "print(\"y_test shape:\", np.shape(y_test))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float().requires_grad_(), torch.from_numpy(y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(x_validate).float().requires_grad_(), torch.from_numpy(y_validate).float())\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test).float().requires_grad_(), torch.from_numpy(y_test).float())\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[128, 64], kernel_size=(3,3), num_layers=2, \n",
    "                 physics_kernel_size=(3,3), output_dim=1, batch_first=True, bias=True, \n",
    "                 return_all_layers=False, window_size=8, num_heads=4)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        # Enable gradients for the output tensor\n",
    "        output.requires_grad_(True)\n",
    "        \n",
    "        # Compute data loss\n",
    "        \n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Compute physics loss\n",
    "\n",
    "        # Create an empty tensor with the same shape as batch_x\n",
    "        rin_physics = torch.zeros_like(batch_x, device=device, requires_grad=True)\n",
    "        #rin_physics = update_grid(rin_physics.cpu().detach().numpy())\n",
    "        # print(rin_physics.shape, batch_x.shape)\n",
    "        # print(\"Shape after update_grid:\", rin_physics.shape)\n",
    "       # rin_physics = rin_physics.view(32, 40, 40, 4)  # Use view instead of reshape\n",
    "        rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n",
    "        \n",
    "        output, _ = model(rin_physics)\n",
    "        physics_loss = model.advection_loss(rin_physics, output)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss   +  physics_loss \n",
    "        \n",
    "        # loss = torch.max(0.5 * torch.abs(data_loss - physics_loss))\n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update weights and velocities\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, _ = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            \n",
    "            # Compute data loss\n",
    "            data_loss = criterion(output, batch_y)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Combine losses\n",
    "            loss = data_loss \n",
    "            \n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "       \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        # Compute data loss\n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss \n",
    "        \n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ],
   "id": "6798790d41b24543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (588, 40, 40, 4)\n",
      "x_validate shape: (196, 40, 40, 4)\n",
      "x_test shape: (196, 40, 40, 4)\n",
      "y_train shape: (588, 40, 40, 1)\n",
      "y_validate shape: (196, 40, 40, 1)\n",
      "y_test shape: (196, 40, 40, 1)\n",
      "Epoch [1/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_127549/3717421570.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 5.70 GiB of which 2.94 MiB is free. Process 16555 has 1.18 GiB memory in use. Process 109271 has 2.78 GiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 18.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 68\u001B[0m\n\u001B[1;32m     65\u001B[0m rin_physics \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(rin_physics,dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32,device\u001B[38;5;241m=\u001B[39mdevice, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Move back to GPU if needed\u001B[39;00m\n\u001B[1;32m     67\u001B[0m output, _ \u001B[38;5;241m=\u001B[39m model(rin_physics)\n\u001B[0;32m---> 68\u001B[0m physics_loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39madvection_loss(rin_physics, output)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# Combine losses\u001B[39;00m\n\u001B[1;32m     71\u001B[0m loss \u001B[38;5;241m=\u001B[39m data_loss   \u001B[38;5;241m+\u001B[39m  physics_loss \n",
      "Cell \u001B[0;32mIn[7], line 218\u001B[0m, in \u001B[0;36mConvLSTM.advection_loss\u001B[0;34m(self, input_tensor, output_tensor)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madvection_loss\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_tensor, output_tensor):\n\u001B[0;32m--> 218\u001B[0m     grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(outputs\u001B[38;5;241m=\u001B[39moutput_tensor, inputs\u001B[38;5;241m=\u001B[39minput_tensor,\n\u001B[1;32m    219\u001B[0m                                grad_outputs\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mones_like(output_tensor), create_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    220\u001B[0m     dudx \u001B[38;5;241m=\u001B[39m grad[:, :, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    221\u001B[0m     dudy \u001B[38;5;241m=\u001B[39m grad[:, :, \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/pinn/lib/python3.11/site-packages/torch/autograd/__init__.py:411\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001B[0m\n\u001B[1;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(\n\u001B[1;32m    408\u001B[0m         grad_outputs_\n\u001B[1;32m    409\u001B[0m     )\n\u001B[1;32m    410\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 411\u001B[0m     result \u001B[38;5;241m=\u001B[39m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    412\u001B[0m         t_outputs,\n\u001B[1;32m    413\u001B[0m         grad_outputs_,\n\u001B[1;32m    414\u001B[0m         retain_graph,\n\u001B[1;32m    415\u001B[0m         create_graph,\n\u001B[1;32m    416\u001B[0m         inputs,\n\u001B[1;32m    417\u001B[0m         allow_unused,\n\u001B[1;32m    418\u001B[0m         accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    419\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m materialize_grads:\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m    422\u001B[0m         result[i] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tensor_like(inputs[i])\n\u001B[1;32m    423\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(inputs))\n\u001B[1;32m    424\u001B[0m     ):\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 5.70 GiB of which 2.94 MiB is free. Process 16555 has 1.18 GiB memory in use. Process 109271 has 2.78 GiB memory in use. Including non-PyTorch memory, this process has 1.71 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 18.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T10:14:17.018521Z",
     "start_time": "2024-06-24T10:14:08.660136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "\n",
    "def animate_comparison(model, data_loader, output_folder):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract a single batch for visualization\n",
    "    inputs, targets = next(iter(data_loader))\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = inputs.to(next(model.parameters()).device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs,states = model(inputs)\n",
    "    \n",
    "    # Assuming outputs and targets are on GPU, move them to CPU and convert to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    \n",
    "    # Prepare figure for animation\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    def update(i):\n",
    "        # Clear previous content\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "        \n",
    "        # Update content for frame i\n",
    "        ax[0].imshow(outputs[i].squeeze(), cmap='gray')\n",
    "        ax[0].set_title('Output')\n",
    "        ax[1].imshow(targets[i].squeeze(), cmap='gray')\n",
    "        ax[1].set_title('Target')\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(outputs), interval=200)\n",
    "    \n",
    "    # Save animation\n",
    "    anim.save(f'{output_folder}/convLSTM_attention_physics_comparison_animation.gif', writer='imagemagick')\n",
    "\n",
    "# Example usage\n",
    "animate_comparison(model, test_loader, '/home/sushen/PhysNet-RadarNowcast/images/convLSTM_attention_ipinn')"
   ],
   "id": "7370c7b763a59edc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
