{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:52:04.756509Z",
     "start_time": "2024-06-25T04:52:04.753168Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:38:33.694820Z",
     "start_time": "2024-06-25T04:38:33.524254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShiftingWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        pad_h = (self.window_size - H % self.window_size) % self.window_size\n",
    "        pad_w = (self.window_size - W % self.window_size) % self.window_size\n",
    "        x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h))\n",
    "        _, Hp, Wp, _ = x.shape\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, self.window_size, Wp // self.window_size, self.window_size, C)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size * self.window_size, C)\n",
    "\n",
    "        qkv = self.qkv(windows).reshape(-1, self.window_size * self.window_size, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(-1, self.window_size * self.window_size, C)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, Wp // self.window_size, self.window_size, self.window_size, C)\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, Hp, Wp, C)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = x[:, :H, :W, :].contiguous()\n",
    "        return x\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias, physics_kernel_size, window_size, num_heads):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.physics_conv_x = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[0] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.physics_conv_y = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[1] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.attention = ShiftingWindowAttention(hidden_dim, window_size, num_heads)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        if input_tensor.dim() == 5:\n",
    "            input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "        if input_tensor.size(1) != self.input_dim:\n",
    "            raise ValueError(f\"Expected input_tensor to have {self.input_dim} channels, but got {input_tensor.size(1)} channels instead\")\n",
    "\n",
    "        if h_cur.size(1) != self.hidden_dim:\n",
    "            raise ValueError(f\"Expected h_cur to have {self.hidden_dim} channels, but got {h_cur.size(1)} channels instead\")\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "\n",
    "        physics_conv_x = self.physics_conv_x(input_tensor)\n",
    "        physics_conv_y = self.physics_conv_y(input_tensor)\n",
    "\n",
    "        i = torch.sigmoid(cc_i + physics_conv_x)\n",
    "        f = torch.sigmoid(cc_f + physics_conv_x)\n",
    "        o = torch.sigmoid(cc_o + physics_conv_y)\n",
    "        g = torch.tanh(cc_g + physics_conv_y)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        # Apply shifting window attention\n",
    "        h_next = h_next.permute(0, 2, 3, 1)  # Change to (B, H, W, C)\n",
    "        h_next = self.attention(h_next)\n",
    "        h_next = h_next.permute(0, 3, 1, 2)  # Change back to (B, C, H, W)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, physics_kernel_size, output_dim,\n",
    "                 batch_first=False, bias=True, return_all_layers=False, window_size=8, num_heads=4):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias,\n",
    "                                          physics_kernel_size=physics_kernel_size,\n",
    "                                          window_size=window_size,\n",
    "                                          num_heads=num_heads))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.output_conv = nn.Conv2d(in_channels=hidden_dim[-1],\n",
    "                                     out_channels=output_dim,\n",
    "                                     kernel_size=1,\n",
    "                                     padding=0)\n",
    "        # Initialize velocities as trainable parameters\n",
    "        self.velocity_x = nn.Parameter(torch.tensor(0.1))\n",
    "        self.velocity_y = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "   \n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        if input_tensor.dim() == 4:\n",
    "            # (b, h, w, c) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "        elif input_tensor.dim() == 5:\n",
    "            if not self.batch_first:\n",
    "                # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "                input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, t, _, h, w = input_tensor.size()\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        # Remove the sequence length dimension before applying the output convolution\n",
    "        output = self.output_conv(layer_output_list[0].squeeze(1))\n",
    "        # Permute the output to have shape (b, h, w, c)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        return output, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param\n",
    "    \n",
    "    def advection_loss(self, input_tensor, output_tensor):\n",
    "        grad = torch.autograd.grad(outputs=output_tensor, inputs=input_tensor,\n",
    "                                   grad_outputs=torch.ones_like(output_tensor), create_graph=True)[0]\n",
    "        dudx = grad[:, :, 0]\n",
    "        dudy = grad[:, :, 1]\n",
    "        dudt = grad[:, :, 2]\n",
    "\n",
    "        physics = dudt + self.velocity_x * dudx + self.velocity_y * dudy\n",
    "        loss = torch.mean((physics) ** 2)\n",
    "\n",
    "        return loss"
   ],
   "id": "f2290a98f0fe48bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:02:34.859226Z",
     "start_time": "2024-06-25T05:02:34.434033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load radar data\n",
    "movies = np.load('/home/sushen/PhysNet-RadarNowcast/src/datasets/rect_movie.npy')\n",
    "movies.shape # (980, 40, 40, 20) -- here each movie is of length 20\n",
    "\n",
    "# in our model we will use the first four images as inputs and predict the\n",
    "# fifth image\n",
    "x = movies[:, :, :,  :4]\n",
    "y = movies[:, :, :, 4:5]\n",
    "\n",
    "\n",
    "# function: animation of a sequence of radar data (shape = nx,ny,ntime)\n",
    "def animate(x):\n",
    "  fig, ax = plt.subplots()\n",
    "  vmax = np.max(x)\n",
    "  im = ax.imshow(x[:,:,0], vmin=0, vmax=vmax)\n",
    "  fig.colorbar(im)\n",
    "  plt.axis('off')\n",
    "  def anim_(i):\n",
    "      im.set_data(x[:,:,i])\n",
    "      ax.set_title(str(i+1) + '/' + str(x.shape[2]))\n",
    "  anim = animation.FuncAnimation(\n",
    "      fig, anim_, interval=300, frames=x.shape[2], repeat_delay=1000)\n",
    "  plt.show()\n",
    "\n",
    "# i_plt = 340\n",
    "# i_plt = 123\n",
    "i_plt = np.int32(np.random.sample() * movies.shape[0])\n",
    "animate(x[i_plt,:,:,:])\n",
    "plt.show()\n",
    "\n",
    "# train validate test split\n",
    "tvt = np.tile(['train','train','train','validate','test'], y.shape[0])[:y.shape[0]]\n",
    "x_train = x[np.where(tvt == 'train')]\n",
    "y_train = y[np.where(tvt == 'train')]\n",
    "x_validate = x[np.where(tvt == 'validate')]\n",
    "y_validate = y[np.where(tvt == 'validate')]\n",
    "x_test = x[np.where(tvt == 'test')]\n",
    "y_test = y[np.where(tvt == 'test')]\n",
    "\n",
    "n_test = x_test.shape[0]\n",
    "i_plt = np.int32(np.random.sample() * n_test)\n",
    "true = np.append(x_test[i_plt,:,:,:], y_test[i_plt,:,:,:], axis=2)\n",
    "# plot an input/output pair\n",
    "i_plt = 20\n",
    "i_plt = np.int32(np.random.sample() * x_train.shape[0])\n",
    "for jj in range(4):\n",
    "  plt.subplot(1,5,jj+1)\n",
    "  plt.imshow(x_train[i_plt,:,:,jj])\n",
    "  plt.axis('off')\n",
    "  plt.title('input')\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(y_train[i_plt,:,:,0])\n",
    "plt.title('target output')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming x_train, x_validate, x_test, y_train, y_validate, and y_test are defined\n",
    "print(\"x_train shape:\", np.shape(x_train))\n",
    "print(\"x_validate shape:\", np.shape(x_validate))\n",
    "print(\"x_test shape:\", np.shape(x_test))\n",
    "print(\"y_train shape:\", np.shape(y_train))\n",
    "print(\"y_validate shape:\", np.shape(y_validate))\n",
    "print(\"y_test shape:\", np.shape(y_test))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float().requires_grad_(), torch.from_numpy(y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(x_validate).float().requires_grad_(), torch.from_numpy(y_validate).float())\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test).float().requires_grad_(), torch.from_numpy(y_test).float())\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "e61b4bc43c4f8cce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushen/anaconda3/envs/pinn/lib/python3.11/site-packages/matplotlib/animation.py:892: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (588, 40, 40, 4)\n",
      "x_validate shape: (196, 40, 40, 4)\n",
      "x_test shape: (196, 40, 40, 4)\n",
      "y_train shape: (588, 40, 40, 1)\n",
      "y_validate shape: (196, 40, 40, 1)\n",
      "y_test shape: (196, 40, 40, 1)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:38:35.756812Z",
     "start_time": "2024-06-25T04:38:34.053424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "def update_grid(rin_physics):\n",
    "    # Get the shape of the input tensor\n",
    "    shape = rin_physics.shape\n",
    "    # Create an empty tensor with the same shape\n",
    "    updated_grid = np.zeros(shape)\n",
    "\n",
    "    # Iterate through each element in the batch\n",
    "    for i in range(shape[0]):\n",
    "        # Extract the individual grid\n",
    "        grid = rin_physics[i]\n",
    "\n",
    "        # Find the max and min x, y values\n",
    "        max_x, max_y = np.unravel_index(np.argmax(grid[:, :, 0]), grid[:, :, 0].shape)\n",
    "        min_x, min_y = np.unravel_index(np.argmin(grid[:, :, 0]), grid[:, :, 0].shape)\n",
    "\n",
    "        # Set the pattern\n",
    "        updated_grid[i, max_x, max_y, :] = 1\n",
    "        updated_grid[i, min_x, min_y, :] = 0\n",
    "\n",
    "    return updated_grid"
   ],
   "id": "c2ce273010cdf8ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:08:08.177426Z",
     "start_time": "2024-06-25T05:02:40.116563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[128, 64], kernel_size=(3,3), num_layers=2, \n",
    "                 physics_kernel_size=(3,3), output_dim=1, batch_first=True, bias=True, \n",
    "                 return_all_layers=False, window_size=1, num_heads=8)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 50\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        # Enable gradients for the output tensor\n",
    "        output.requires_grad_(True)\n",
    "        \n",
    "        # Compute data loss\n",
    "        \n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Compute physics loss\n",
    "\n",
    "        # Create an empty tensor with the same shape as batch_x\n",
    "        rin_physics = torch.zeros_like(batch_x, device=device, requires_grad=True)\n",
    "        rin_physics = update_grid(rin_physics.cpu().detach().numpy())\n",
    "        # print(rin_physics.shape, batch_x.shape)\n",
    "        # print(\"Shape after update_grid:\", rin_physics.shape)\n",
    "       # rin_physics = rin_physics.view(32, 40, 40, 4)  # Use view instead of reshape\n",
    "        rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n",
    "        \n",
    "        output, _ = model(rin_physics)\n",
    "        physics_loss = model.advection_loss(rin_physics, output)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss   +  physics_loss \n",
    "        \n",
    "        # loss = torch.max(0.5 * torch.abs(data_loss - physics_loss))\n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update weights and velocities\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, _ = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            \n",
    "            # Compute data loss\n",
    "            data_loss = criterion(output, batch_y)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Combine losses\n",
    "            loss = data_loss \n",
    "            \n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "       \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        # Compute data loss\n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss \n",
    "        \n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ],
   "id": "6798790d41b24543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Train Loss: 0.0034, Val Loss: 0.0028\n",
      "Epoch [2/50]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [3/50]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [4/50]\n",
      "Train Loss: 0.0026, Val Loss: 0.0024\n",
      "Epoch [5/50]\n",
      "Train Loss: 0.0023, Val Loss: 0.0023\n",
      "Epoch [6/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [7/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [8/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [9/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [10/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [11/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [12/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [13/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [14/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [15/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [16/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [17/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [18/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [19/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [20/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [21/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [22/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [23/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [24/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [25/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [26/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [27/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [28/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [29/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [30/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [31/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [32/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [33/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [34/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [35/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [36/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [37/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [38/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [39/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [40/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [41/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [42/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [43/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [44/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [45/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [46/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [47/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [48/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [49/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [50/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Test Loss: 0.0021\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:17:02.394623Z",
     "start_time": "2024-06-25T05:17:02.376066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "torch.save(model.state_dict(), '/home/sushen/PhysNet-RadarNowcast/src/models/convLSTM_attention_physics_dynamic_grid.pth'  )\n"
   ],
   "id": "3b3006ccea91728e",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:21.038209Z",
     "start_time": "2024-06-25T05:21:21.008402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[128, 64], kernel_size=(3,3), num_layers=2,\n",
    "                 physics_kernel_size=(3,3), output_dim=1, batch_first=True, bias=True,\n",
    "                 return_all_layers=False, window_size=1, num_heads=8)\n",
    "\n",
    "# Specify the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model parameters from a .pth file\n",
    "model.load_state_dict(torch.load(\"/home/sushen/PhysNet-RadarNowcast/src/models/convLSTM_attention_physics_dynamic_grid.pth\"\n",
    "                                 \"\", map_location=device))\n",
    "\n",
    "model.eval()"
   ],
   "id": "ad82194c6c6dd343",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (conv): Conv2d(132, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (physics_conv_x): Conv2d(4, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (physics_conv_y): Conv2d(4, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (attention): ShiftingWindowAttention(\n",
       "        (qkv): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvLSTMCell(\n",
       "      (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (physics_conv_x): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (physics_conv_y): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (attention): ShiftingWindowAttention(\n",
       "        (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:33.555654Z",
     "start_time": "2024-06-25T05:21:23.532209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "\n",
    "def animate_comparison(model, data_loader, output_folder):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract a single batch for visualization\n",
    "    inputs, targets = next(iter(data_loader))\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = inputs.to(next(model.parameters()).device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs,states = model(inputs)\n",
    "    \n",
    "    # Assuming outputs and targets are on GPU, move them to CPU and convert to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    \n",
    "    # Prepare figure for animation\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    def update(i):\n",
    "        # Clear previous content\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "        \n",
    "        # Update content for frame i\n",
    "        ax[0].imshow(outputs[i].squeeze(), cmap='viridis')\n",
    "        ax[0].set_title('Output')\n",
    "        ax[1].imshow(targets[i].squeeze(), cmap='viridis')\n",
    "        ax[1].set_title('Target')\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(outputs), interval=2000)\n",
    "    \n",
    "    # Save animation\n",
    "    anim.save(f'{output_folder}/convLSTM_attention_physics_comparison_animation.gif', writer='imagemagick')\n",
    "\n",
    "# Example usage\n",
    "animate_comparison(model, test_loader, '/home/sushen/PhysNet-RadarNowcast/images/convLSTM_attention_ipinn')"
   ],
   "id": "7370c7b763a59edc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
