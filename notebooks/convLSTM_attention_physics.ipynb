{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T10:45:13.557510Z",
     "start_time": "2024-06-24T10:45:13.326710Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T10:51:02.614070Z",
     "start_time": "2024-06-24T10:51:02.595911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ShiftingWindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        pad_h = (self.window_size - H % self.window_size) % self.window_size\n",
    "        pad_w = (self.window_size - W % self.window_size) % self.window_size\n",
    "        x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h))\n",
    "        _, Hp, Wp, _ = x.shape\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, self.window_size, Wp // self.window_size, self.window_size, C)\n",
    "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, self.window_size * self.window_size, C)\n",
    "\n",
    "        qkv = self.qkv(windows).reshape(-1, self.window_size * self.window_size, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(-1, self.window_size * self.window_size, C)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        x = x.view(B, Hp // self.window_size, Wp // self.window_size, self.window_size, self.window_size, C)\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, Hp, Wp, C)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = x[:, :H, :W, :].contiguous()\n",
    "        return x\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias, physics_kernel_size, window_size, num_heads):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        self.physics_conv_x = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[0] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.physics_conv_y = nn.Conv2d(in_channels=self.input_dim,\n",
    "                                        out_channels=self.hidden_dim,\n",
    "                                        kernel_size=physics_kernel_size,\n",
    "                                        padding=physics_kernel_size[1] // 2,\n",
    "                                        bias=False)\n",
    "\n",
    "        self.attention = ShiftingWindowAttention(hidden_dim, window_size, num_heads)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        if input_tensor.dim() == 5:\n",
    "            input_tensor = input_tensor.squeeze(1)\n",
    "\n",
    "        if input_tensor.size(1) != self.input_dim:\n",
    "            raise ValueError(f\"Expected input_tensor to have {self.input_dim} channels, but got {input_tensor.size(1)} channels instead\")\n",
    "\n",
    "        if h_cur.size(1) != self.hidden_dim:\n",
    "            raise ValueError(f\"Expected h_cur to have {self.hidden_dim} channels, but got {h_cur.size(1)} channels instead\")\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "\n",
    "        physics_conv_x = self.physics_conv_x(input_tensor)\n",
    "        physics_conv_y = self.physics_conv_y(input_tensor)\n",
    "\n",
    "        i = torch.sigmoid(cc_i + physics_conv_x)\n",
    "        f = torch.sigmoid(cc_f + physics_conv_x)\n",
    "        o = torch.sigmoid(cc_o + physics_conv_y)\n",
    "        g = torch.tanh(cc_g + physics_conv_y)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        # Apply shifting window attention\n",
    "        h_next = h_next.permute(0, 2, 3, 1)  # Change to (B, H, W, C)\n",
    "        h_next = self.attention(h_next)\n",
    "        h_next = h_next.permute(0, 3, 1, 2)  # Change back to (B, C, H, W)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, physics_kernel_size, output_dim,\n",
    "                 batch_first=False, bias=True, return_all_layers=False, window_size=8, num_heads=4):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias,\n",
    "                                          physics_kernel_size=physics_kernel_size,\n",
    "                                          window_size=window_size,\n",
    "                                          num_heads=num_heads))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.output_conv = nn.Conv2d(in_channels=hidden_dim[-1],\n",
    "                                     out_channels=output_dim,\n",
    "                                     kernel_size=1,\n",
    "                                     padding=0)\n",
    "        # Initialize velocities as trainable parameters\n",
    "        self.velocity_x = nn.Parameter(torch.tensor(0.1))\n",
    "        self.velocity_y = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "   \n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        if input_tensor.dim() == 4:\n",
    "            # (b, h, w, c) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(0, 3, 1, 2).unsqueeze(1)\n",
    "        elif input_tensor.dim() == 5:\n",
    "            if not self.batch_first:\n",
    "                # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "                input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, t, _, h, w = input_tensor.size()\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        # Remove the sequence length dimension before applying the output convolution\n",
    "        output = self.output_conv(layer_output_list[0].squeeze(1))\n",
    "        # Permute the output to have shape (b, h, w, c)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        return output, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param\n",
    "    \n",
    "    def advection_loss(self, input_tensor, output_tensor):\n",
    "        grad = torch.autograd.grad(outputs=output_tensor, inputs=input_tensor,\n",
    "                                   grad_outputs=torch.ones_like(output_tensor), create_graph=True)[0]\n",
    "        dudx = grad[:, :, 0]\n",
    "        dudy = grad[:, :, 1]\n",
    "        dudt = grad[:, :, 2]\n",
    "\n",
    "        physics = dudt + self.velocity_x * dudx + self.velocity_y * dudy\n",
    "        loss = torch.mean((physics) ** 2)\n",
    "\n",
    "        return loss"
   ],
   "id": "f2290a98f0fe48bf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T10:48:31.972632Z",
     "start_time": "2024-06-24T10:48:31.487161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load radar data\n",
    "movies = np.load('/home/sushen/PhysNet-RadarNowcast/tests/rect_movie.npy')\n",
    "movies.shape # (980, 40, 40, 20) -- here each movie is of length 20\n",
    "\n",
    "# in our model we will use the first four images as inputs and predict the\n",
    "# fifth image\n",
    "x = movies[:, :, :,  :4]\n",
    "y = movies[:, :, :, 4:5]\n",
    "\n",
    "\n",
    "# function: animation of a sequence of radar data (shape = nx,ny,ntime)\n",
    "def animate(x):\n",
    "  fig, ax = plt.subplots()\n",
    "  vmax = np.max(x)\n",
    "  im = ax.imshow(x[:,:,0], vmin=0, vmax=vmax)\n",
    "  fig.colorbar(im)\n",
    "  plt.axis('off')\n",
    "  def anim_(i):\n",
    "      im.set_data(x[:,:,i])\n",
    "      ax.set_title(str(i+1) + '/' + str(x.shape[2]))\n",
    "  anim = animation.FuncAnimation(\n",
    "      fig, anim_, interval=300, frames=x.shape[2], repeat_delay=1000)\n",
    "  plt.show()\n",
    "\n",
    "# i_plt = 340\n",
    "# i_plt = 123\n",
    "i_plt = np.int32(np.random.sample() * movies.shape[0])\n",
    "animate(x[i_plt,:,:,:])\n",
    "plt.show()\n",
    "\n",
    "# train validate test split\n",
    "tvt = np.tile(['train','train','train','validate','test'], y.shape[0])[:y.shape[0]]\n",
    "x_train = x[np.where(tvt == 'train')]\n",
    "y_train = y[np.where(tvt == 'train')]\n",
    "x_validate = x[np.where(tvt == 'validate')]\n",
    "y_validate = y[np.where(tvt == 'validate')]\n",
    "x_test = x[np.where(tvt == 'test')]\n",
    "y_test = y[np.where(tvt == 'test')]\n",
    "\n",
    "n_test = x_test.shape[0]\n",
    "i_plt = np.int32(np.random.sample() * n_test)\n",
    "true = np.append(x_test[i_plt,:,:,:], y_test[i_plt,:,:,:], axis=2)\n",
    "# plot an input/output pair\n",
    "i_plt = 20\n",
    "i_plt = np.int32(np.random.sample() * x_train.shape[0])\n",
    "for jj in range(4):\n",
    "  plt.subplot(1,5,jj+1)\n",
    "  plt.imshow(x_train[i_plt,:,:,jj])\n",
    "  plt.axis('off')\n",
    "  plt.title('input')\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(y_train[i_plt,:,:,0])\n",
    "plt.title('target output')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "e61b4bc43c4f8cce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushen/anaconda3/envs/pinn/lib/python3.11/site-packages/matplotlib/animation.py:892: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.memory_summary(device=None, abbreviated=False)",
   "id": "c2ce273010cdf8ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T11:04:08.980724Z",
     "start_time": "2024-06-24T10:58:47.812978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming x_train, x_validate, x_test, y_train, y_validate, and y_test are defined\n",
    "print(\"x_train shape:\", np.shape(x_train))\n",
    "print(\"x_validate shape:\", np.shape(x_validate))\n",
    "print(\"x_test shape:\", np.shape(x_test))\n",
    "print(\"y_train shape:\", np.shape(y_train))\n",
    "print(\"y_validate shape:\", np.shape(y_validate))\n",
    "print(\"y_test shape:\", np.shape(y_test))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "train_dataset = TensorDataset(torch.from_numpy(x_train).float().requires_grad_(), torch.from_numpy(y_train).float())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.from_numpy(x_validate).float().requires_grad_(), torch.from_numpy(y_validate).float())\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(x_test).float().requires_grad_(), torch.from_numpy(y_test).float())\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[128, 64], kernel_size=(3,3), num_layers=2, \n",
    "                 physics_kernel_size=(3,3), output_dim=1, batch_first=True, bias=True, \n",
    "                 return_all_layers=False, window_size=1, num_heads=8)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 50\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        # Enable gradients for the output tensor\n",
    "        output.requires_grad_(True)\n",
    "        \n",
    "        # Compute data loss\n",
    "        \n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Compute physics loss\n",
    "\n",
    "        # Create an empty tensor with the same shape as batch_x\n",
    "        rin_physics = torch.zeros_like(batch_x, device=device, requires_grad=True)\n",
    "        #rin_physics = update_grid(rin_physics.cpu().detach().numpy())\n",
    "        # print(rin_physics.shape, batch_x.shape)\n",
    "        # print(\"Shape after update_grid:\", rin_physics.shape)\n",
    "       # rin_physics = rin_physics.view(32, 40, 40, 4)  # Use view instead of reshape\n",
    "        rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n",
    "        \n",
    "        output, _ = model(rin_physics)\n",
    "        physics_loss = model.advection_loss(rin_physics, output)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss   +  physics_loss \n",
    "        \n",
    "        # loss = torch.max(0.5 * torch.abs(data_loss - physics_loss))\n",
    "        # Backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update weights and velocities\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, _ = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            \n",
    "            # Compute data loss\n",
    "            data_loss = criterion(output, batch_y)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Combine losses\n",
    "            loss = data_loss \n",
    "            \n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "       \n",
    "        # Forward pass\n",
    "        output, _ = model(batch_x)\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        # Compute data loss\n",
    "        data_loss = criterion(output, batch_y)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = data_loss \n",
    "        \n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ],
   "id": "6798790d41b24543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (588, 40, 40, 4)\n",
      "x_validate shape: (196, 40, 40, 4)\n",
      "x_test shape: (196, 40, 40, 4)\n",
      "y_train shape: (588, 40, 40, 1)\n",
      "y_validate shape: (196, 40, 40, 1)\n",
      "y_test shape: (196, 40, 40, 1)\n",
      "Epoch [1/50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171783/2411064478.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rin_physics = torch.tensor(rin_physics,dtype=torch.float32,device=device, requires_grad=True)  # Move back to GPU if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0043, Val Loss: 0.0031\n",
      "Epoch [2/50]\n",
      "Train Loss: 0.0028, Val Loss: 0.0029\n",
      "Epoch [3/50]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [4/50]\n",
      "Train Loss: 0.0027, Val Loss: 0.0028\n",
      "Epoch [5/50]\n",
      "Train Loss: 0.0026, Val Loss: 0.0024\n",
      "Epoch [6/50]\n",
      "Train Loss: 0.0023, Val Loss: 0.0023\n",
      "Epoch [7/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [8/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [9/50]\n",
      "Train Loss: 0.0022, Val Loss: 0.0022\n",
      "Epoch [10/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [11/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [12/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [13/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [14/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [15/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [16/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [17/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [18/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [19/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [20/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [21/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [22/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [23/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [24/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [25/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [26/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [27/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [28/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [29/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [30/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [31/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [32/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [33/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [34/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [35/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [36/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [37/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [38/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [39/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [40/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [41/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [42/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [43/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [44/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [45/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [46/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [47/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [48/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [49/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Epoch [50/50]\n",
      "Train Loss: 0.0021, Val Loss: 0.0022\n",
      "Test Loss: 0.0021\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T11:05:13.306398Z",
     "start_time": "2024-06-24T11:05:06.100681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "\n",
    "def animate_comparison(model, data_loader, output_folder):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Extract a single batch for visualization\n",
    "    inputs, targets = next(iter(data_loader))\n",
    "    \n",
    "    # Move inputs to the same device as the model\n",
    "    inputs = inputs.to(next(model.parameters()).device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs,states = model(inputs)\n",
    "    \n",
    "    # Assuming outputs and targets are on GPU, move them to CPU and convert to numpy\n",
    "    outputs = outputs.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    \n",
    "    # Prepare figure for animation\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    def update(i):\n",
    "        # Clear previous content\n",
    "        ax[0].cla()\n",
    "        ax[1].cla()\n",
    "        \n",
    "        # Update content for frame i\n",
    "        ax[0].imshow(outputs[i].squeeze(), cmap='gray')\n",
    "        ax[0].set_title('Output')\n",
    "        ax[1].imshow(targets[i].squeeze(), cmap='gray')\n",
    "        ax[1].set_title('Target')\n",
    "    \n",
    "    # Create animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(outputs), interval=200)\n",
    "    \n",
    "    # Save animation\n",
    "    anim.save(f'{output_folder}/convLSTM_attention_physics_comparison_animation.gif', writer='imagemagick')\n",
    "\n",
    "# Example usage\n",
    "animate_comparison(model, test_loader, '/home/sushen/PhysNet-RadarNowcast/images/convLSTM_attention_ipinn')"
   ],
   "id": "7370c7b763a59edc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
